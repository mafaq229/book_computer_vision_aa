{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a simple application to change the color balance of an image\n",
    "by multiplying each color value by a different user-specified constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_color_balance(image_path, alpha=1.0, beta=1.0, gamma=1.0):\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    B, G, R = cv2.split(image)\n",
    "    R = R * alpha\n",
    "    G = G * beta\n",
    "    B = B * gamma\n",
    "    \n",
    "    new_image = cv2.merge([B, G, R])\n",
    "    # we can use both clipping and normalization. I prefer normalization however select clipping (reason explained later)\n",
    "    # normalized_new_image = cv2.normalize(new_image, None, 0, 255, cv2.NORM_MINMAX) \n",
    "    normalized_new_image = np.clip(new_image, 0, 255)\n",
    "    return normalized_new_image\n",
    "\n",
    "image_path = 'image.png'\n",
    "alpha, beta, gamma = 1.2, 1.0, 0.8\n",
    "balanced_img = adjust_color_balance(image_path, alpha, beta, gamma)\n",
    "\n",
    "original = cv2.imread(image_path)\n",
    "cv2.imshow(\"original\", original)\n",
    "cv2.imshow(\"balanced_image\", balanced_img.astype(np.uint8))\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"color_balanced_image.png\", balanced_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you get different results if you take out the gamma transformation before or after doing the multiplication? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gamma correction is a non-linear transformation applied to images to adjust brightness and contrast in a way that aligns with human vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gamma(image, gamma):\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    # Build a lookup table mapping the pixel values [0, 255] to their adjusted gamma values\n",
    "    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(256)])\n",
    "    transformed_image = cv2.LUT(image, table)\n",
    "    return transformed_image\n",
    "\n",
    "\n",
    "def adjust_color_balance_with_gamma(image_path, alpha=1.0, beta=1.0, gamma=1.0, apply_gamma_transformation_first=True, gamma_transformation_value=2.2):\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    if apply_gamma_transformation_first:\n",
    "        image = apply_gamma(image, gamma_transformation_value)\n",
    "    \n",
    "    B, G, R = cv2.split(image)\n",
    "    R = R * alpha\n",
    "    G = G * beta\n",
    "    B = B * gamma\n",
    "    \n",
    "    new_image = cv2.merge([B, G, R])\n",
    "    # we can use both clipping and normalization. I prefer normalization\n",
    "    normalized_new_image = cv2.normalize(new_image, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    # normalized_new_image = np.clip(new_image, 0, 255)\n",
    "    \n",
    "    if not apply_gamma_transformation_first:\n",
    "        image = apply_gamma(image, gamma_transformation_value)\n",
    "    \n",
    "    return normalized_new_image\n",
    "\n",
    "\n",
    "alpha, beta, gamma = 1.2, 1.0, 0.8\n",
    "gamma_value = 2.2  # Common gamma value\n",
    "\n",
    "# Gamma before scaling\n",
    "balanced_img_gamma_first = adjust_color_balance_with_gamma(\n",
    "    image_path, alpha, beta, gamma, True, gamma_value)\n",
    "\n",
    "# Gamma after scaling\n",
    "balanced_img_gamma_last = adjust_color_balance_with_gamma(\n",
    "    image_path, alpha, beta, gamma, False, gamma_value)\n",
    "\n",
    "cv2.imshow(\"original\", original)\n",
    "cv2.imshow(\"balanced_image_gamma_first\", balanced_img_gamma_first.astype(np.uint8))\n",
    "cv2.imshow(\"balanced_image_gamma_last\", balanced_img_gamma_last.astype(np.uint8))\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we get different results by applying gamma transformation before and after color balancing. This is because gamma correction is a non-linear operation. The order in which these operations are applied affects how the scaling factors influence the final image's luminance and color balance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the same picture with your digital camera using different color balance settings\n",
    "(most cameras control the color balance from one of the menus). Can you recover what\n",
    "the color balance ratios are between the different settings? You may need to put your\n",
    "camera on a tripod and align the images manually or automatically to make this work.\n",
    "Alternatively, use a color checker chart (Figure 10.3b), as discussed in Sections 2.3 and\n",
    "10.1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19361249248255 0.9989999746495232 0.7958366635878162\n"
     ]
    }
   ],
   "source": [
    "def compute_color_balance_ratios(image_path_A, image_path_B, num_samples=100):\n",
    "    \"\"\"\n",
    "    Compute the color balance ratios between two images by sampling corresponding pixels.\n",
    "    \n",
    "    :param image_path_A: Path to image A (first setting)\n",
    "    :param image_path_B: Path to image B (second setting)\n",
    "    :param num_samples: Number of random samples to compute the ratios\n",
    "    :return: (alpha, beta, gamma) scaling factors\n",
    "    \"\"\"\n",
    "    # Load images\n",
    "    image_A = cv2.imread(image_path_A)\n",
    "    image_B = cv2.imread(image_path_B)\n",
    "    \n",
    "    # Ensure both images have the same dimensions\n",
    "    if image_A.shape != image_B.shape:\n",
    "        print(\"Error: Images do not have the same dimensions.\")\n",
    "        return\n",
    "    \n",
    "    # Flatten the images to a list of pixels channelwise\n",
    "    pixels_A = image_A.reshape(-1, 3)\n",
    "    pixels_B = image_B.reshape(-1, 3)\n",
    "    \n",
    "    # Randomly select sample pixels\n",
    "    indices = np.random.choice(pixels_A.shape[0], num_samples, replace=False)\n",
    "    sampled_A = pixels_A[indices]\n",
    "    sampled_B = pixels_B[indices]\n",
    "    \n",
    "    # Compute ratios, avoiding division by zero\n",
    "    ratios = sampled_B / (sampled_A + 1e-6)\n",
    "    \n",
    "    # Compute average ratios for each channel\n",
    "    alpha = np.mean(ratios[:,2])  # Red channel\n",
    "    beta = np.mean(ratios[:,1])   # Green channel\n",
    "    gamma = np.mean(ratios[:,0])  # Blue channel\n",
    "    \n",
    "    return alpha, beta, gamma\n",
    "\n",
    "# Example usage\n",
    "image_path_A = 'image.png'\n",
    "image_path_B = 'color_balanced_image.png'\n",
    "alpha, beta, gamma = compute_color_balance_ratios(image_path_A, image_path_B, 1000)\n",
    "print(alpha, beta, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interesting thing I noticed is that you will not get accurate value if you had performed normalization, instead of clipping, while color balancing (normalization changes pixel value hence ratio is not maintained)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you think of any reason why you might want to perform a color twist (Sec-\n",
    "tion 3.1.2) on the images? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_twist(image_path, hue_shift=0, saturation_scale=1.0, brightness_scale=1.0):\n",
    "    \"\"\"\n",
    "    Perform a color twist on an image by adjusting hue, saturation, and brightness.\n",
    "    \n",
    "    :param image_path: Path to the input image\n",
    "    :param hue_shift: Degrees to shift the hue (0-180 in OpenCV)\n",
    "    :param saturation_scale: Scaling factor for saturation\n",
    "    :param brightness_scale: Scaling factor for brightness/value\n",
    "    :return: Twisted image in RGB format\n",
    "    \"\"\"\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path).astype(np.float32)\n",
    "    \n",
    "    # Convert to HSV\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Adjust Hue\n",
    "    hsv[:, :, 0] = (hsv[:, :, 0] + hue_shift) % 180  # Hue values in OpenCV are [0,179]\n",
    "    \n",
    "    # Adjust Saturation\n",
    "    hsv[:, :, 1] = hsv[:, :, 1] * saturation_scale\n",
    "    hsv[:, :, 1] = np.clip(hsv[:, :, 1], 0, 255)\n",
    "    \n",
    "    # Adjust Brightness/Value\n",
    "    hsv[:, :, 2] = hsv[:, :, 2] * brightness_scale\n",
    "    hsv[:, :, 2] = np.clip(hsv[:, :, 2], 0, 255)\n",
    "    \n",
    "    # Convert back to BGR\n",
    "    twisted_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    return twisted_image\n",
    "\n",
    "# Example usage\n",
    "image_path = 'image.png'\n",
    "hue_shift = 100  # Shift hue by 10 degrees\n",
    "saturation_scale = 1.2  # Increase saturation by 20%\n",
    "brightness_scale = 1.1  # Increase brightness by 10%\n",
    "\n",
    "twisted_img = color_twist(image_path, hue_shift, saturation_scale, brightness_scale)\n",
    "\n",
    "original = cv2.imread(image_path)\n",
    "\n",
    "cv2.imshow(\"original\", original)\n",
    "\n",
    "# since cv2.imshow() displays image in uint8 format so we see artefacts\n",
    "# save image to disk and view it for accurate results  \n",
    "cv2.imshow(\"twisted image\", twisted_img.astype(np.uint8))\n",
    "# cv2.imwrite(\"twisted_image.png\", twisted_img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Color Twist involves altering the hue, saturation, or brightness of an image to achieve desired visual effects or correct color imbalances. It's a form of color transformation that can enhance the aesthetic appeal or correct color issues in images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
